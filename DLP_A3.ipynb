{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y3AqoZD--ZYf",
        "outputId": "670db1fb-46b5-4e7d-9f84-cbb3ffe46ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to the TrainIJCNN2013 folder\n",
        "train_folder_path = '/content/drive/MyDrive/DLP_A3/TrainIJCNN2013/TrainIJCNN2013'\n",
        "\n",
        "# List all files and folders, but filter out only the folders\n",
        "subfolders = [f for f in os.listdir(train_folder_path) if os.path.isdir(os.path.join(train_folder_path, f))]\n",
        "\n",
        "# Print the list of subfolders\n",
        "#print(subfolders)\n",
        "print(len(subfolders))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3NpW91S-voO",
        "outputId": "daa6b6c9-7a4f-48e7-e724-5405cb74a718"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categories = {\n",
        "    '00': 'speed limit 20 (prohibitory)', '01': 'speed limit 30 (prohibitory)', '02': 'speed limit 50 (prohibitory)',\n",
        "    '03': 'speed limit 60 (prohibitory)', '04': 'speed limit 70 (prohibitory)', '05': 'speed limit 80 (prohibitory)',\n",
        "    '06': 'restriction ends 80 (other)', '07': 'speed limit 100 (prohibitory)', '08': 'speed limit 120 (prohibitory)',\n",
        "    '09': 'no overtaking (prohibitory)', '10': 'no overtaking (trucks) (prohibitory)', '11': 'priority at next intersection (danger)',\n",
        "    '12': 'priority road (other)', '13': 'give way (other)', '14': 'stop (other)', '15': 'no traffic both ways (prohibitory)',\n",
        "    '16': 'no trucks (prohibitory)', '17': 'no entry (other)', '18': 'danger (danger)', '19': 'bend left (danger)',\n",
        "    '20': 'bend right (danger)', '21': 'bend (danger)', '22': 'uneven road (danger)', '23': 'slippery road (danger)',\n",
        "    '24': 'road narrows (danger)', '25': 'construction (danger)', '26': 'traffic signal (danger)', '27': 'pedestrian crossing (danger)',\n",
        "    '28': 'school crossing (danger)', '29': 'cycles crossing (danger)', '30': 'snow (danger)', '31': 'animals (danger)',\n",
        "    '32': 'restriction ends (other)', '33': 'go right (mandatory)', '34': 'go left (mandatory)', '35': 'go straight (mandatory)',\n",
        "    '36': 'go right or straight (mandatory)', '37': 'go left or straight (mandatory)', '38': 'keep right (mandatory)',\n",
        "    '39': 'keep left (mandatory)', '40': 'roundabout (mandatory)', '41': 'restriction ends (overtaking) (other)',\n",
        "    '42': 'restriction ends (overtaking (trucks)) (other)'\n",
        "}"
      ],
      "metadata": {
        "id": "f8xlA-mIA98C"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Preprocessing function\n",
        "def preprocess_image(img, target_size=(32, 32)):\n",
        "    img = cv2.resize(img, target_size)  # Resize the image\n",
        "    img = img / 255.0  # Normalize the image\n",
        "    return img\n",
        "\n",
        "# Load the images and labels\n",
        "def load_data(base_path, categories):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for category_index, category_name in categories.items():\n",
        "        category_folder = os.path.join(base_path, category_index)  # Use string folder names like '00', '01'\n",
        "        image_files = [f for f in os.listdir(category_folder) if f.endswith('.ppm')]\n",
        "\n",
        "        for image_file in image_files:\n",
        "            img_path = os.path.join(category_folder, image_file)  # Full path to image\n",
        "            img = cv2.imread(img_path)  # Read image\n",
        "            img = preprocess_image(img)  # Preprocess image\n",
        "            images.append(img)\n",
        "            labels.append(int(category_index))  # Convert string index to int for label\n",
        "\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "\n",
        "    return images, labels\n",
        "\n",
        "# Load the data\n",
        "X, y = load_data(train_folder_path, categories)\n",
        "\n",
        "# Split data into train and validation sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "wIR7nXWRFeB0"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Create the CNN model\n",
        "def create_cnn_model(input_shape=(32, 32, 3), num_classes=43):\n",
        "    model = tf.keras.models.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "    model.add(tf.keras.layers.Flatten())\n",
        "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "    model.add(tf.keras.layers.Dropout(0.5))\n",
        "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "# Create and train the model\n",
        "model = create_cnn_model(input_shape=(32, 32, 3), num_classes=43)\n",
        "history = model.fit(X_train, y_train, epochs=30, batch_size=32)\n",
        "\n",
        "train_accuracy = history.history['accuracy'][-1]  # Get the last epoch's accuracy\n",
        "print(f'Training Accuracy: {train_accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhU15MeOI07j",
        "outputId": "797a2ce1-d8d3-4136-e95e-f0d9b48d8a61"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.0441 - loss: 3.6846\n",
            "Epoch 2/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.0957 - loss: 3.4554\n",
            "Epoch 3/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.1501 - loss: 3.2758\n",
            "Epoch 4/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.2759 - loss: 2.9350\n",
            "Epoch 5/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.3372 - loss: 2.6425\n",
            "Epoch 6/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.3823 - loss: 2.3405\n",
            "Epoch 7/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.4083 - loss: 2.0976\n",
            "Epoch 8/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - accuracy: 0.4732 - loss: 1.8740\n",
            "Epoch 9/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.4970 - loss: 1.6932\n",
            "Epoch 10/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.5281 - loss: 1.5882\n",
            "Epoch 11/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.5800 - loss: 1.4119\n",
            "Epoch 12/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.6146 - loss: 1.2700\n",
            "Epoch 13/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.6868 - loss: 1.1173\n",
            "Epoch 14/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.7303 - loss: 0.9123\n",
            "Epoch 15/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.7667 - loss: 0.8014\n",
            "Epoch 16/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7521 - loss: 0.8278\n",
            "Epoch 17/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.7796 - loss: 0.6943\n",
            "Epoch 18/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8090 - loss: 0.6548\n",
            "Epoch 19/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8249 - loss: 0.5631\n",
            "Epoch 20/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.8774 - loss: 0.4685\n",
            "Epoch 21/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8648 - loss: 0.4707\n",
            "Epoch 22/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.8729 - loss: 0.4072\n",
            "Epoch 23/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.8895 - loss: 0.3341\n",
            "Epoch 24/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.8951 - loss: 0.4166\n",
            "Epoch 25/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9193 - loss: 0.3254\n",
            "Epoch 26/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9281 - loss: 0.2627\n",
            "Epoch 27/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9286 - loss: 0.2708\n",
            "Epoch 28/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9230 - loss: 0.2620\n",
            "Epoch 29/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9259 - loss: 0.2474\n",
            "Epoch 30/30\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9549 - loss: 0.1723\n",
            "Training Accuracy: 0.9516\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
        "model.save('traffic_sign_classifier.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaeL4WncJVGU",
        "outputId": "37ebc486-bba0-4f93-f98a-6cbe77574476"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8739 - loss: 0.6458\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Path to the image you want to classify\n",
        "img_path = '/content/00003.ppm'\n",
        "\n",
        "# Load the image with target size as per your model input shape (e.g., 32x32)\n",
        "img = image.load_img(img_path, target_size=(32, 32))  # Adjust target_size as needed\n",
        "\n",
        "# Convert image to a numpy array\n",
        "img_array = image.img_to_array(img)\n",
        "\n",
        "# Normalize the image data (if your model was trained with normalized data)\n",
        "img_array = img_array / 255.0  # If you normalized images to [0, 1] range during training\n",
        "\n",
        "# Add an extra dimension to the image to match the input shape (batch_size, height, width, channels)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Predict the class for the image\n",
        "predicted_class = model.predict(img_array)\n",
        "\n",
        "# Get the index of the maximum value (the predicted class)\n",
        "predicted_class_index = np.argmax(predicted_class)\n",
        "\n",
        "# Define the class names (traffic sign labels)\n",
        "class_names = [\n",
        "    \"speed limit 20 (prohibitory)\", \"speed limit 30 (prohibitory)\", \"speed limit 50 (prohibitory)\",\n",
        "    \"speed limit 60 (prohibitory)\", \"speed limit 70 (prohibitory)\", \"speed limit 80 (prohibitory)\",\n",
        "    \"restriction ends 80 (other)\", \"speed limit 100 (prohibitory)\", \"speed limit 120 (prohibitory)\",\n",
        "    \"no overtaking (prohibitory)\", \"no overtaking (trucks) (prohibitory)\", \"priority at next intersection (danger)\",\n",
        "    \"priority road (other)\", \"give way (other)\", \"stop (other)\", \"no traffic both ways (prohibitory)\",\n",
        "    \"no trucks (prohibitory)\", \"no entry (other)\", \"danger (danger)\", \"bend left (danger)\", \"bend right (danger)\",\n",
        "    \"bend (danger)\", \"uneven road (danger)\", \"slippery road (danger)\", \"road narrows (danger)\",\n",
        "    \"construction (danger)\", \"traffic signal (danger)\", \"pedestrian crossing (danger)\", \"school crossing (danger)\",\n",
        "    \"cycles crossing (danger)\", \"snow (danger)\", \"animals (danger)\", \"restriction ends (other)\",\n",
        "    \"go right (mandatory)\", \"go left (mandatory)\", \"go straight (mandatory)\", \"go right or straight (mandatory)\",\n",
        "    \"go left or straight (mandatory)\", \"keep right (mandatory)\", \"keep left (mandatory)\", \"roundabout (mandatory)\",\n",
        "    \"restriction ends (overtaking) (other)\", \"restriction ends (overtaking (trucks)) (other)\"\n",
        "]\n",
        "\n",
        "# Get the predicted label\n",
        "predicted_label = class_names[predicted_class_index]\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(img)\n",
        "plt.axis('off')  # Turn off axis labels\n",
        "plt.title(f'Predicted: {predicted_label}')\n",
        "plt.show()\n",
        "\n",
        "print(f'Predicted label: {predicted_label}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "VzCrvikgQ_mt",
        "outputId": "f7329011-5f97-4c3c-8460-4bc3985b65a3"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted label: restriction ends (overtaking (trucks)) (other)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8Kh4ZRMR9o9",
        "outputId": "11ed23ba-af35-4ec5-d528-461ae2dc6b00"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.40.1)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLQHllUBSKs7",
        "outputId": "40ac3596-be40-435c-a56d-03d08015fc04"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok config add-authtoken 2nNJOyHu7o5yYPe1YbtAqOLdwn0_3NESFS1Q5Y3gVgoefUQEs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlGZ4yWFVE13",
        "outputId": "21f70fbf-3ffc-4f16-ec4b-0714e2be4928"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGdZR2wXV5Sh",
        "outputId": "92059227-fc74-40d4-f5cc-b299421cfde8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# Set up the streamlit tunnel on port 8501 (default port)\n",
        "public_url = ngrok.connect(8501)\n",
        "\n",
        "# Run the Streamlit app in the background\n",
        "os.system(\"streamlit run app.py &\")\n",
        "\n",
        "print(f\"Streamlit app is live at {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FoIY9egrSx5k",
        "outputId": "c5b46fd6-4685-40d2-8379-2d4c4dded6c6"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit app is live at NgrokTunnel: \"https://66f3-35-237-132-176.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image as PILImage\n",
        "\n",
        "# Load the trained model (Assuming the model is already saved)\n",
        "try:\n",
        "    model = load_model('/content/traffic_sign_classifier.h5')\n",
        "    st.write(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    st.error(f\"Error loading model: {str(e)}\")\n",
        "    model = None\n",
        "\n",
        "# Define class names for the traffic signs\n",
        "class_names = [\n",
        "    \"speed limit 20 (prohibitory)\", \"speed limit 30 (prohibitory)\", \"speed limit 50 (prohibitory)\",\n",
        "    \"speed limit 60 (prohibitory)\", \"speed limit 70 (prohibitory)\", \"speed limit 80 (prohibitory)\",\n",
        "    \"restriction ends 80 (other)\", \"speed limit 100 (prohibitory)\", \"speed limit 120 (prohibitory)\",\n",
        "    \"no overtaking (prohibitory)\", \"no overtaking (trucks) (prohibitory)\", \"priority at next intersection (danger)\",\n",
        "    \"priority road (other)\", \"give way (other)\", \"stop (other)\", \"no traffic both ways (prohibitory)\",\n",
        "    \"no trucks (prohibitory)\", \"no entry (other)\", \"danger (danger)\", \"bend left (danger)\", \"bend right (danger)\",\n",
        "    \"bend (danger)\", \"uneven road (danger)\", \"slippery road (danger)\", \"road narrows (danger)\",\n",
        "    \"construction (danger)\", \"traffic signal (danger)\", \"pedestrian crossing (danger)\", \"school crossing (danger)\",\n",
        "    \"cycles crossing (danger)\", \"snow (danger)\", \"animals (danger)\", \"restriction ends (other)\",\n",
        "    \"go right (mandatory)\", \"go left (mandatory)\", \"go straight (mandatory)\", \"go right or straight (mandatory)\",\n",
        "    \"go left or straight (mandatory)\", \"keep right (mandatory)\", \"keep left (mandatory)\", \"roundabout (mandatory)\",\n",
        "    \"restriction ends (overtaking) (other)\", \"restriction ends (overtaking (trucks)) (other)\"\n",
        "]\n",
        "\n",
        "# Function to process the uploaded image\n",
        "def process_image(image_file):\n",
        "    img = image.load_img(image_file, target_size=(32, 32))  # Adjust the target size based on your model input\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = img_array / 255.0  # Normalization if you did that during training\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    return img_array, img\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"German Traffic Sign Classifier\")\n",
        "\n",
        "st.write(\"Upload an image of a traffic sign, and the model will predict the class.\")\n",
        "\n",
        "# File uploader\n",
        "uploaded_file = st.file_uploader(\"Choose an image...\", type=[\"ppm\", \"png\", \"jpg\", \"jpeg\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    # Process the uploaded image\n",
        "    img_array, img = process_image(uploaded_file)\n",
        "\n",
        "    # Display the uploaded image\n",
        "    st.image(img, caption='Uploaded Image', use_column_width=True)\n",
        "\n",
        "    # Make prediction if model is loaded\n",
        "    if model:\n",
        "        predicted_class = model.predict(img_array)\n",
        "        predicted_class_index = np.argmax(predicted_class)\n",
        "        predicted_label = class_names[predicted_class_index]\n",
        "\n",
        "        # Display prediction result\n",
        "        st.write(f\"Predicted class: {predicted_label}\")\n",
        "    else:\n",
        "        st.error(\"Model not loaded. Please check the model file.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtJuC13rVNK1",
        "outputId": "decb18e5-81d9-4979-d03d-82d950257b50"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    }
  ]
}